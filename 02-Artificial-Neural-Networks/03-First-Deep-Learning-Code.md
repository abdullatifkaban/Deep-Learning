# Ä°lk Derin Ã–ÄŸrenme Modelimiz: MNIST Rakam SÄ±nÄ±flandÄ±rma

Bu Ã¶rnekte, el yazÄ±sÄ± rakamlarÄ± tanÄ±yan basit bir derin Ã¶ÄŸrenme modeli oluÅŸturacaÄŸÄ±z. MNIST veri setini kullanarak, 0-9 arasÄ±ndaki rakamlarÄ± sÄ±nÄ±flandÄ±ran bir sinir aÄŸÄ± geliÅŸtireceÄŸiz.

## 1. Gerekli KÃ¼tÃ¼phanelerin Ä°Ã§e AktarÄ±lmasÄ±

```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
```

> [!NOTE]
> TensorFlow, derin Ã¶ÄŸrenme modelimizi oluÅŸturmak iÃ§in kullanacaÄŸÄ±mÄ±z ana kÃ¼tÃ¼phane.
> NumPy, veri manipÃ¼lasyonu iÃ§in, Matplotlib ise gÃ¶rselleÅŸtirme iÃ§in kullanÄ±lacak.

## 2. Veri Setinin YÃ¼klenmesi ve Ã–n Ä°ÅŸleme

```python
# MNIST veri setini yÃ¼kle
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# GÃ¶rÃ¼ntÃ¼leri normalize et (0-1 arasÄ±na Ã¶lÃ§ekle)
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

print('EÄŸitim veri seti boyutu:', x_train.shape)
print('Test veri seti boyutu:', x_test.shape)
```
EÄŸitim veri seti boyutu: (60000, 28, 28)<br>
Test veri seti boyutu: (10000, 28, 28)

> [!TIP]
> - Veri setini 0-1 arasÄ±na Ã¶lÃ§ekleme (normalizasyon), modelin daha iyi Ã¶ÄŸrenmesini saÄŸlar
> - MNIST veri seti 60,000 eÄŸitim ve 10,000 test gÃ¶rÃ¼ntÃ¼sÃ¼ iÃ§erir
> - Her gÃ¶rÃ¼ntÃ¼ 28x28 piksel boyutundadÄ±r

## 3. Veri GÃ¶rselleÅŸtirme

```python
# Rastgele 5 gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶rselleÅŸtir
plt.figure(figsize=(10, 2))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(f'Rakam: {y_train[i]}')
    plt.axis('off')
plt.show()
```
![output](images/output-01.png)

## 4. Model Mimarisi

```python
model = tf.keras.Sequential([
    # GiriÅŸ katmanÄ± - gÃ¶rÃ¼ntÃ¼yÃ¼ dÃ¼zleÅŸtir
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    
    # Gizli katman 1
    tf.keras.layers.Dense(128, activation='relu'),
    
    # Dropout katmanÄ± - aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in
    tf.keras.layers.Dropout(0.2),
    
    # Gizli katman 2
    tf.keras.layers.Dense(64, activation='relu'),
    
    # Ã‡Ä±kÄ±ÅŸ katmanÄ± - 10 sÄ±nÄ±f iÃ§in (0-9 rakamlarÄ±)
    tf.keras.layers.Dense(10, activation='softmax')
])
```

> [!IMPORTANT]
> Model mimarisinin aÃ§Ä±klamasÄ±:
> 1. `Flatten`: 28x28 gÃ¶rÃ¼ntÃ¼yÃ¼ 784 boyutlu bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
> 2. Ä°lk `Dense` katman: 128 nÃ¶ronlu gizli katman, ReLU aktivasyonu kullanÄ±r
> 3. `Dropout`: AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in nÃ¶ronlarÄ±n %20'sini rastgele devre dÄ±ÅŸÄ± bÄ±rakÄ±r
> 4. Ä°kinci `Dense` katman: 64 nÃ¶ronlu gizli katman
> 5. Son katman: Her rakam iÃ§in bir olasÄ±lÄ±k deÄŸeri Ã¼reten 10 nÃ¶ronlu Ã§Ä±kÄ±ÅŸ katmanÄ±

## 5. Model Derleme

```python
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Model Ã¶zetini gÃ¶rÃ¼ntÃ¼le
model.summary()
```

> [!NOTE]
> - `optimizer`: AÄŸÄ±rlÄ±klarÄ± gÃ¼ncellemek iÃ§in Adam optimizasyon algoritmasÄ± kullanÄ±lÄ±yor
> - `loss`: SÄ±nÄ±flandÄ±rma problemi iÃ§in uygun kayÄ±p fonksiyonu
> - `metrics`: Model baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in doÄŸruluk metriÄŸi kullanÄ±lÄ±yor

## 6. Model EÄŸitimi

```python
history = model.fit(
    x_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)
```

Model: "sequential"

| Layer (type)        | Output Shape       | Param #     |
|---------------------|--------------------|-------------|
| flatten (Flatten)   | (None, 784)        | 0           |
| dense (Dense)       | (None, 128)        | 100,480     |
| dropout (Dropout)   | (None, 128)        | 0           |
| dense_1 (Dense)     | (None, 64)         | 8,256       |
| dense_2 (Dense)     | (None, 10)         | 650         |

Total params: 109,386 (427.29 KB)  
Trainable params: 109,386 (427.29 KB)  
Non-trainable params: 0 (0.00 B)

> [!TIP]
> EÄŸitim parametreleri:
> - `epochs`: Veri seti Ã¼zerinden 10 kez geÃ§ilecek
> - `batch_size`: Her seferde 32 gÃ¶rÃ¼ntÃ¼ iÅŸlenecek
> - `validation_split`: EÄŸitim verisinin %20'si doÄŸrulama iÃ§in ayrÄ±lacak

## 7. EÄŸitim SonuÃ§larÄ±nÄ±n GÃ¶rselleÅŸtirilmesi

```python
plt.figure(figsize=(12, 4))

# DoÄŸruluk grafiÄŸi
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='EÄŸitim DoÄŸruluÄŸu')
plt.plot(history.history['val_accuracy'], label='DoÄŸrulama DoÄŸruluÄŸu')
plt.title('Model DoÄŸruluÄŸu')
plt.xlabel('Epoch')
plt.ylabel('DoÄŸruluk')
plt.legend()

# KayÄ±p grafiÄŸi
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='EÄŸitim KaybÄ±')
plt.plot(history.history['val_loss'], label='DoÄŸrulama KaybÄ±')
plt.title('Model KaybÄ±')
plt.xlabel('Epoch')
plt.ylabel('KayÄ±p')
plt.legend()

plt.show()
```

## 8. Test Veri Seti Ãœzerinde DeÄŸerlendirme

```python
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print(f'\nTest DoÄŸruluÄŸu: {test_accuracy:.4f}')
```

## 9. Tahmin Ã–rneÄŸi

```python
# Test setinden rastgele 5 gÃ¶rÃ¼ntÃ¼ seÃ§ ve tahmin yap
test_images = x_test[:5]
predictions = model.predict(test_images)

plt.figure(figsize=(10, 2))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(test_images[i], cmap='gray')
    pred_label = np.argmax(predictions[i])
    true_label = y_test[i]
    plt.title(f'T:{true_label} P:{pred_label}')
    plt.axis('off')
plt.show()
```

## ğŸ“š Ã–nerilen Kaynaklar
- [TensorFlow MNIST Tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner)
- [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)
- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
