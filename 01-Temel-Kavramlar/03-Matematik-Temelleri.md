# Matematik Temelleri

## ğŸ“ BÃ¶lÃ¼m HaritasÄ±
- Ã–nceki BÃ¶lÃ¼m: [Python ve KÃ¼tÃ¼phaneler](02-Python-Kutuphaneler.md)
- Sonraki BÃ¶lÃ¼m: [Perceptron ve Sinir HÃ¼creleri](../02-Yapay-Sinir-Aglari/01-Perceptron.md)
- Tahmini SÃ¼re: 4-5 saat
- Zorluk Seviyesi: ğŸŸ¢ BaÅŸlangÄ±Ã§

## ğŸ¯ Hedefler
- Derin Ã¶ÄŸrenme iÃ§in gerekli matematik kavramlarÄ±nÄ± anlama
- Temel lineer cebir ve kalkÃ¼lÃ¼s bilgisi edinme
- Optimizasyon ve olasÄ±lÄ±k teorisi temellerini Ã¶ÄŸrenme
- Matematiksel notasyonu ve terminolojiyi kavrama

## ğŸ¯ Ã–z DeÄŸerlendirme
- [ ] Temel lineer cebir iÅŸlemlerini yapabiliyorum
- [ ] TÃ¼rev ve integral kavramlarÄ±nÄ± anlayabildim
- [ ] Optimizasyon problemlerini Ã§Ã¶zebiliyorum
- [ ] OlasÄ±lÄ±k ve istatistik hesaplamalarÄ±nÄ± yapabiliyorum

## ğŸš€ Mini Projeler
1. Gradyan Ä°niÅŸ SimÃ¼lasyonu
   - 2D ve 3D fonksiyonlar iÃ§in gradyan iniÅŸi uygulayÄ±n
   - FarklÄ± Ã¶ÄŸrenme oranlarÄ±nÄ±n etkisini gÃ¶zlemleyin
   - SonuÃ§larÄ± gÃ¶rselleÅŸtirin

2. Matris Ä°ÅŸlemleri UygulamasÄ±
   - Temel matris operasyonlarÄ±nÄ± iÃ§eren bir kÃ¼tÃ¼phane yazÄ±n
   - Sinir aÄŸÄ± hesaplamalarÄ±nÄ± manuel olarak gerÃ§ekleÅŸtirin
   - Numpy sonuÃ§larÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±n

## ğŸ“‘ Ã–n KoÅŸullar
- Temel matematik bilgisi
- Fonksiyon kavramÄ±
- Grafik okuma ve yorumlama
- Temel problem Ã§Ã¶zme becerisi

## ğŸ”‘ Temel Kavramlar
1. Lineer Cebir
2. KalkÃ¼lÃ¼s
3. OlasÄ±lÄ±k ve Ä°statistik
4. Optimizasyon
5. Matris Ä°ÅŸlemleri

## Lineer Cebir
> ğŸ’¡ Ä°pucu: Matris iÅŸlemlerini iyi anlamak, derin Ã¶ÄŸrenme modellerinin Ã§alÄ±ÅŸma prensibini kavramayÄ± kolaylaÅŸtÄ±rÄ±r

### 1. VektÃ¶rler ve Matrisler
```python
import numpy as np

# VektÃ¶r oluÅŸturma
v = np.array([1, 2, 3])

# Matris oluÅŸturma
A = np.array([[1, 2], [3, 4]])
```

### 2. TÃ¼rev
TÃ¼rev, bir fonksiyonun anlÄ±k deÄŸiÅŸim oranÄ±dÄ±r ve gradyan iniÅŸte kullanÄ±lÄ±r.

```python
# Otomatik tÃ¼rev hesaplama
x = tf.Variable(3.0)
with tf.GradientTape() as tape:
    y = x * x  # y = x^2
dy_dx = tape.gradient(y, x)  # dy/dx = 2x
```

### 3. KÄ±smi TÃ¼revler
Ã‡ok deÄŸiÅŸkenli fonksiyonlarÄ±n her bir deÄŸiÅŸkene gÃ¶re tÃ¼revi.

```python
# KÄ±smi tÃ¼revler
x = tf.Variable(2.0)
y = tf.Variable(3.0)
with tf.GradientTape() as tape:
    z = x*x + y*y  # z = x^2 + y^2
gradients = tape.gradient(z, [x, y])  # [âˆ‚z/âˆ‚x, âˆ‚z/âˆ‚y]
```

### 4. Gradyan
TÃ¼m kÄ±smi tÃ¼revlerin oluÅŸturduÄŸu vektÃ¶r.

```python
def compute_gradients(model, x, y):
    with tf.GradientTape() as tape:
        loss = tf.keras.losses.mean_squared_error(y, model(x))
    return tape.gradient(loss, model.trainable_variables)
```

## OlasÄ±lÄ±k ve Ä°statistik

### 1. Temel Kavramlar
```python
# Ortalama ve standart sapma
data = tf.constant([1, 2, 2, 3, 4, 5, 5])
mean = tf.reduce_mean(data)
std = tf.math.reduce_std(data)

# OlasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±
probs = tf.nn.softmax([1.0, 2.0, 3.0])  # Kategorik daÄŸÄ±lÄ±m
```

### 2. OlasÄ±lÄ±k DaÄŸÄ±lÄ±mlarÄ±

#### Normal DaÄŸÄ±lÄ±m
```python
# Normal daÄŸÄ±lÄ±mdan Ã¶rnekleme
samples = tf.random.normal(shape=[1000], mean=0.0, stddev=1.0)

# Histogram Ã§izimi
import matplotlib.pyplot as plt
plt.hist(samples.numpy(), bins=30)
plt.title('Normal DaÄŸÄ±lÄ±m')
plt.show()
```

## Optimizasyon

### 1. Gradyan Ä°niÅŸ
```python
# Basit gradyan iniÅŸ
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)

def train_step(model, x, y):
    with tf.GradientTape() as tape:
        predictions = model(x)
        loss = tf.keras.losses.mean_squared_error(y, predictions)
    
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss
```

### 2. Optimizasyon AlgoritmalarÄ±
```python
# Adam optimizer
adam = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999
)

# RMSprop optimizer
rmsprop = tf.keras.optimizers.RMSprop(
    learning_rate=0.001,
    rho=0.9
)
```

## Matris Ä°ÅŸlemleri

### 1. Determinant ve Ters Matris
```python
# 3x3 matris oluÅŸturun
matrix = tf.random.normal([3, 3])

# Determinant hesaplama
det = tf.linalg.det(matrix)

# Ters matris
inv = tf.linalg.inv(matrix)
```

### 2. TÃ¼rev ve Ä°ntegral
```python
# f(x) = xÂ³ + 2xÂ² - 4x + 1
x = tf.Variable(2.0)
with tf.GradientTape() as tape:
    y = x**3 + 2*x**2 - 4*x + 1
dy_dx = tape.gradient(y, x)
```

## ğŸ“š Ã–nerilen Kaynaklar
- [Khan Academy Mathematics](https://www.khanacademy.org/math)
- [3Blue1Brown Linear Algebra](https://www.3blue1brown.com/topics/linear-algebra)
- [Deep Learning Book - Math Chapters](https://www.deeplearningbook.org/contents/part_basics.html)

## âœï¸ AlÄ±ÅŸtÄ±rmalar
### BaÅŸlangÄ±Ã§ Seviyesi
1. Temel matris iÅŸlemleri
2. TÃ¼rev ve integral hesaplamalarÄ±

### Orta Seviye
1. Optimizasyon problemleri Ã§Ã¶zme
2. Ä°statistiksel analiz uygulamalarÄ±

### Ä°leri Seviye
1. Gradyan hesaplamalarÄ±
2. OlasÄ±lÄ±k daÄŸÄ±lÄ±mlarÄ± analizi 