# Ãœretici Ã‡ekiÅŸmeli AÄŸlar (GANs)

## ğŸ“ BÃ¶lÃ¼m HaritasÄ±
- Ã–nceki BÃ¶lÃ¼m: [Transfer Learning](01-Transfer-Learning.md)
- Sonraki BÃ¶lÃ¼m: [Reinforcement Learning](03-Reinforcement-Learning.md)
- Tahmini SÃ¼re: 6-7 saat
- Zorluk Seviyesi: ğŸ”´ Ä°leri

## ğŸ¯ Hedefler
- GAN mimarisini detaylÄ± anlama
- Generator ve Discriminator yapÄ±larÄ±nÄ± kavrama
- FarklÄ± GAN tÃ¼rlerini Ã¶ÄŸrenme
- Modern GAN uygulamalarÄ± geliÅŸtirme

## ğŸ¯ Ã–z DeÄŸerlendirme
- [ ] GAN mimarisini aÃ§Ä±klayabiliyorum
- [ ] Generator ve Discriminator yapÄ±larÄ±nÄ± anlayabiliyorum
- [ ] FarklÄ± GAN tÃ¼rlerini kullanabiliyorum
- [ ] Mode collapse problemini Ã§Ã¶zebiliyorum

## ğŸš€ Mini Projeler
1. DCGAN
   - YÃ¼z Ã¼retimi
   - Style transfer
   - Latent space analizi

2. Conditional GAN
   - Etiket tabanlÄ± Ã¼retim
   - Cross-domain transfer
   - Attribute manipulation

## ğŸ“‘ Ã–n KoÅŸullar
- Derin Ã¶ÄŸrenme temelleri
- CNN mimarisi bilgisi
- Python ve framework deneyimi
- Optimizasyon teknikleri

## ğŸ”‘ Temel Kavramlar
1. Generator
2. Discriminator
3. Adversarial Training
4. Mode Collapse

## GiriÅŸ

GANs (Generative Adversarial Networks), Ã¼retici ve ayÄ±rt edici olmak Ã¼zere iki aÄŸÄ±n birbirleriyle rekabet ederek Ã¶ÄŸrendiÄŸi derin Ã¶ÄŸrenme modelidir.

## Temel GAN Mimarisi

### 1. Generator (Ãœretici)
```python
import tensorflow as tf

def build_generator(latent_dim):
    model = tf.keras.Sequential([
        # BaÅŸlangÄ±Ã§ katmanÄ±
        tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(latent_dim,)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.Reshape((7, 7, 256)),
        
        # Upsampling katmanlarÄ±
        tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        
        tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        
        # Ã‡Ä±kÄ±ÅŸ katmanÄ±
        tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')
    ])
    return model
```

### 2. Discriminator (AyÄ±rt Edici)
```python
def build_discriminator():
    model = tf.keras.Sequential([
        # GiriÅŸ katmanÄ±
        tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.Dropout(0.3),
        
        # Ã–zellik Ã§Ä±karma katmanlarÄ±
        tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.Dropout(0.3),
        
        # Ã‡Ä±kÄ±ÅŸ katmanÄ±
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1)
    ])
    return model
```

## GAN EÄŸitimi

### 1. Loss FonksiyonlarÄ±
```python
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)
```

### 2. EÄŸitim AdÄ±mÄ±
```python
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])
    
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        # Generator Ã§Ä±ktÄ±sÄ±
        generated_images = generator(noise, training=True)
        
        # Discriminator tahminleri
        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)
        
        # Loss hesaplama
        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)
    
    # GradyanlarÄ± hesapla
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
    
    # Optimize et
    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
```

## GAN TÃ¼rleri

### 1. DCGAN (Deep Convolutional GAN)
```python
def build_dcgan_generator(latent_dim):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(8*8*1024, input_shape=(latent_dim,)),
        tf.keras.layers.Reshape((8, 8, 1024)),
        tf.keras.layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Conv2D(3, kernel_size=3, padding='same', activation='tanh')
    ])
    return model
```

### 2. Conditional GAN
```python
def build_conditional_generator(latent_dim, num_classes):
    # GÃ¼rÃ¼ltÃ¼ giriÅŸi
    noise = tf.keras.layers.Input(shape=(latent_dim,))
    
    # SÄ±nÄ±f etiketi giriÅŸi
    label = tf.keras.layers.Input(shape=(1,))
    label_embedding = tf.keras.layers.Embedding(num_classes, 50)(label)
    label_embedding = tf.keras.layers.Flatten()(label_embedding)
    
    # GÃ¼rÃ¼ltÃ¼ ve etiketi birleÅŸtir
    combined_input = tf.keras.layers.Concatenate()([noise, label_embedding])
    
    # Generator aÄŸÄ±
    x = tf.keras.layers.Dense(7*7*256)(combined_input)
    x = tf.keras.layers.Reshape((7, 7, 256))(x)
    x = tf.keras.layers.Conv2DTranspose(128, 5, strides=2, padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)
    x = tf.keras.layers.Conv2DTranspose(64, 5, strides=2, padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)
    img = tf.keras.layers.Conv2D(1, 5, padding='same', activation='tanh')(x)
    
    return tf.keras.Model([noise, label], img)
```

## Ã–rnek Uygulamalar

### 1. MNIST GAN
```python
# Veri yÃ¼kleme
(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5

# Model oluÅŸturma
generator = build_generator(100)
discriminator = build_discriminator()

# EÄŸitim
EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16

for epoch in range(EPOCHS):
    for image_batch in train_dataset:
        train_step(image_batch)
```

### 2. Style Transfer GAN
```python
def build_style_transfer_model():
    # VGG19 tabanlÄ± Ã¶zellik Ã§Ä±karÄ±cÄ±
    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
    vgg.trainable = False
    
    # Style ve content katmanlarÄ±
    style_outputs = [vgg.get_layer(name).output for name in style_layers]
    content_outputs = [vgg.get_layer(name).output for name in content_layers]
    
    model = tf.keras.Model(vgg.input, style_outputs + content_outputs)
    return model
```

## AlÄ±ÅŸtÄ±rmalar

1. MNIST GAN:
   - Basit GAN modelini implement edin
   - FarklÄ± hiperparametrelerle deneyin
   - Mode collapse problemini gÃ¶zlemleyin

2. Conditional GAN:
   - MNIST Ã¼zerinde cGAN implement edin
   - Belirli rakamlar Ã¼retin
   - SonuÃ§larÄ± deÄŸerlendirin

3. Style Transfer:
   - Style transfer GAN implement edin
   - Kendi resimlerinizle deneyin
   - FarklÄ± style aÄŸÄ±rlÄ±klarÄ±nÄ± test edin

## Kaynaklar
1. [GAN Paper](https://arxiv.org/abs/1406.2661)
2. [DCGAN Tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)
3. [Style Transfer Guide](https://www.tensorflow.org/tutorials/generative/style_transfer) 